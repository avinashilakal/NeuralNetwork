{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test)=reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]\n",
    "len(x_train)\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index=reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in\n",
    "    x_train[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_newswire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=vectorize_sequences(x_train)\n",
    "x_test=vectorize_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 46\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense((64),activation='relu',input_shape=(10000,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense((64),activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense((46),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 647,726\n",
      "Trainable params: 647,470\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8982 samples, validate on 2246 samples\n",
      "Epoch 1/100\n",
      "8982/8982 [==============================] - 4s 417us/step - loss: 3.2954 - acc: 0.2899 - val_loss: 3.2709 - val_acc: 0.5739\n",
      "Epoch 2/100\n",
      "8982/8982 [==============================] - 3s 310us/step - loss: 1.9061 - acc: 0.6108 - val_loss: 2.5805 - val_acc: 0.6776\n",
      "Epoch 3/100\n",
      "8982/8982 [==============================] - 3s 301us/step - loss: 1.4508 - acc: 0.6925 - val_loss: 2.1196 - val_acc: 0.7057\n",
      "Epoch 4/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 1.2371 - acc: 0.7331 - val_loss: 1.7821 - val_acc: 0.7155\n",
      "Epoch 5/100\n",
      "8982/8982 [==============================] - 3s 289us/step - loss: 1.1012 - acc: 0.7592 - val_loss: 1.5215 - val_acc: 0.7333\n",
      "Epoch 6/100\n",
      "8982/8982 [==============================] - 3s 291us/step - loss: 0.9786 - acc: 0.7846 - val_loss: 1.3379 - val_acc: 0.7511\n",
      "Epoch 7/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.8871 - acc: 0.7971 - val_loss: 1.2045 - val_acc: 0.7556\n",
      "Epoch 8/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.8155 - acc: 0.8138 - val_loss: 1.1027 - val_acc: 0.7658\n",
      "Epoch 9/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.7621 - acc: 0.8215 - val_loss: 1.0655 - val_acc: 0.7716\n",
      "Epoch 10/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.6926 - acc: 0.8385 - val_loss: 1.0484 - val_acc: 0.7738\n",
      "Epoch 11/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.6695 - acc: 0.8428 - val_loss: 1.0390 - val_acc: 0.7760\n",
      "Epoch 12/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.6157 - acc: 0.8508 - val_loss: 1.0528 - val_acc: 0.7850\n",
      "Epoch 13/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.5753 - acc: 0.8615 - val_loss: 1.0438 - val_acc: 0.7832\n",
      "Epoch 14/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.5620 - acc: 0.8691 - val_loss: 1.0768 - val_acc: 0.7872\n",
      "Epoch 15/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.5282 - acc: 0.8724 - val_loss: 1.0765 - val_acc: 0.7827\n",
      "Epoch 16/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.4932 - acc: 0.8799 - val_loss: 1.0872 - val_acc: 0.7845\n",
      "Epoch 17/100\n",
      "8982/8982 [==============================] - 3s 297us/step - loss: 0.4888 - acc: 0.8813 - val_loss: 1.0843 - val_acc: 0.7885\n",
      "Epoch 18/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.4578 - acc: 0.8937 - val_loss: 1.1020 - val_acc: 0.7890\n",
      "Epoch 19/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.4393 - acc: 0.8922 - val_loss: 1.1154 - val_acc: 0.7863\n",
      "Epoch 20/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.4145 - acc: 0.8949 - val_loss: 1.1170 - val_acc: 0.7872\n",
      "Epoch 21/100\n",
      "8982/8982 [==============================] - 3s 311us/step - loss: 0.4235 - acc: 0.8949 - val_loss: 1.1410 - val_acc: 0.7863\n",
      "Epoch 22/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.3853 - acc: 0.9028 - val_loss: 1.1563 - val_acc: 0.7867\n",
      "Epoch 23/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.3959 - acc: 0.9039 - val_loss: 1.1444 - val_acc: 0.7930\n",
      "Epoch 24/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.3708 - acc: 0.9085 - val_loss: 1.1716 - val_acc: 0.7912\n",
      "Epoch 25/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.3611 - acc: 0.9100 - val_loss: 1.1688 - val_acc: 0.7934\n",
      "Epoch 26/100\n",
      "8982/8982 [==============================] - 3s 308us/step - loss: 0.3603 - acc: 0.9106 - val_loss: 1.1647 - val_acc: 0.7947\n",
      "Epoch 27/100\n",
      "8982/8982 [==============================] - 3s 306us/step - loss: 0.3496 - acc: 0.9154 - val_loss: 1.1578 - val_acc: 0.7952\n",
      "Epoch 28/100\n",
      "8982/8982 [==============================] - 3s 297us/step - loss: 0.3387 - acc: 0.9162 - val_loss: 1.1877 - val_acc: 0.7921\n",
      "Epoch 29/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.3172 - acc: 0.9204 - val_loss: 1.1900 - val_acc: 0.7930\n",
      "Epoch 30/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.3239 - acc: 0.9191 - val_loss: 1.1915 - val_acc: 0.8001\n",
      "Epoch 31/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.3012 - acc: 0.9260 - val_loss: 1.2073 - val_acc: 0.7965\n",
      "Epoch 32/100\n",
      "8982/8982 [==============================] - 3s 311us/step - loss: 0.3163 - acc: 0.9210 - val_loss: 1.2231 - val_acc: 0.7956\n",
      "Epoch 33/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.3142 - acc: 0.9217 - val_loss: 1.2181 - val_acc: 0.7970\n",
      "Epoch 34/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2943 - acc: 0.9270 - val_loss: 1.2101 - val_acc: 0.7925\n",
      "Epoch 35/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.3177 - acc: 0.9204 - val_loss: 1.2212 - val_acc: 0.7921\n",
      "Epoch 36/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.3073 - acc: 0.9240 - val_loss: 1.2385 - val_acc: 0.7921\n",
      "Epoch 37/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2958 - acc: 0.9243 - val_loss: 1.2365 - val_acc: 0.7939\n",
      "Epoch 38/100\n",
      "8982/8982 [==============================] - 3s 311us/step - loss: 0.3047 - acc: 0.9257 - val_loss: 1.2343 - val_acc: 0.7965\n",
      "Epoch 39/100\n",
      "8982/8982 [==============================] - 3s 301us/step - loss: 0.2856 - acc: 0.9263 - val_loss: 1.2414 - val_acc: 0.7947\n",
      "Epoch 40/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2680 - acc: 0.9294 - val_loss: 1.2548 - val_acc: 0.7925\n",
      "Epoch 41/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2730 - acc: 0.9296 - val_loss: 1.2422 - val_acc: 0.7898\n",
      "Epoch 42/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.2781 - acc: 0.9281 - val_loss: 1.2642 - val_acc: 0.7898\n",
      "Epoch 43/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.2644 - acc: 0.9344 - val_loss: 1.2625 - val_acc: 0.7979\n",
      "Epoch 44/100\n",
      "8982/8982 [==============================] - 3s 311us/step - loss: 0.2582 - acc: 0.9305 - val_loss: 1.2752 - val_acc: 0.7912\n",
      "Epoch 45/100\n",
      "8982/8982 [==============================] - 3s 329us/step - loss: 0.2511 - acc: 0.9336 - val_loss: 1.2847 - val_acc: 0.7961\n",
      "Epoch 46/100\n",
      "8982/8982 [==============================] - 3s 322us/step - loss: 0.2613 - acc: 0.9352 - val_loss: 1.2905 - val_acc: 0.7934\n",
      "Epoch 47/100\n",
      "8982/8982 [==============================] - 3s 323us/step - loss: 0.2577 - acc: 0.9354 - val_loss: 1.2921 - val_acc: 0.7907\n",
      "Epoch 48/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.2302 - acc: 0.9407 - val_loss: 1.2938 - val_acc: 0.7956\n",
      "Epoch 49/100\n",
      "8982/8982 [==============================] - 3s 341us/step - loss: 0.2480 - acc: 0.9342 - val_loss: 1.2912 - val_acc: 0.7952\n",
      "Epoch 50/100\n",
      "8982/8982 [==============================] - 3s 325us/step - loss: 0.2308 - acc: 0.9394 - val_loss: 1.2851 - val_acc: 0.7925\n",
      "Epoch 51/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.2423 - acc: 0.9394 - val_loss: 1.2970 - val_acc: 0.7943\n",
      "Epoch 52/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.2418 - acc: 0.9355 - val_loss: 1.3050 - val_acc: 0.7965\n",
      "Epoch 53/100\n",
      "8982/8982 [==============================] - 3s 310us/step - loss: 0.2481 - acc: 0.9354 - val_loss: 1.2952 - val_acc: 0.7970\n",
      "Epoch 54/100\n",
      "8982/8982 [==============================] - 3s 308us/step - loss: 0.2454 - acc: 0.9358 - val_loss: 1.3051 - val_acc: 0.7979\n",
      "Epoch 55/100\n",
      "8982/8982 [==============================] - 3s 315us/step - loss: 0.2372 - acc: 0.9359 - val_loss: 1.2993 - val_acc: 0.7925\n",
      "Epoch 56/100\n",
      "8982/8982 [==============================] - 3s 317us/step - loss: 0.2437 - acc: 0.9385 - val_loss: 1.2894 - val_acc: 0.7939\n",
      "Epoch 57/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.2348 - acc: 0.9392 - val_loss: 1.3162 - val_acc: 0.7961\n",
      "Epoch 58/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.2308 - acc: 0.9382 - val_loss: 1.3006 - val_acc: 0.7970\n",
      "Epoch 59/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.2440 - acc: 0.9350 - val_loss: 1.3104 - val_acc: 0.8001\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2267 - acc: 0.9395 - val_loss: 1.3195 - val_acc: 0.7992\n",
      "Epoch 61/100\n",
      "8982/8982 [==============================] - 3s 313us/step - loss: 0.2339 - acc: 0.9387 - val_loss: 1.3152 - val_acc: 0.7979\n",
      "Epoch 62/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2302 - acc: 0.9391 - val_loss: 1.3146 - val_acc: 0.7979\n",
      "Epoch 63/100\n",
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2250 - acc: 0.9404 - val_loss: 1.3217 - val_acc: 0.7979\n",
      "Epoch 64/100\n",
      "8982/8982 [==============================] - 3s 285us/step - loss: 0.2344 - acc: 0.9370 - val_loss: 1.3434 - val_acc: 0.7970\n",
      "Epoch 65/100\n",
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2326 - acc: 0.9373 - val_loss: 1.3354 - val_acc: 0.7952\n",
      "Epoch 66/100\n",
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2353 - acc: 0.9394 - val_loss: 1.3111 - val_acc: 0.8001\n",
      "Epoch 67/100\n",
      "8982/8982 [==============================] - 3s 297us/step - loss: 0.2256 - acc: 0.9441 - val_loss: 1.3293 - val_acc: 0.7974\n",
      "Epoch 68/100\n",
      "8982/8982 [==============================] - 3s 299us/step - loss: 0.2206 - acc: 0.9418 - val_loss: 1.3409 - val_acc: 0.7956\n",
      "Epoch 69/100\n",
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2336 - acc: 0.9405 - val_loss: 1.3357 - val_acc: 0.7970\n",
      "Epoch 70/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.2240 - acc: 0.9405 - val_loss: 1.3229 - val_acc: 0.7992\n",
      "Epoch 71/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.2175 - acc: 0.9422 - val_loss: 1.3424 - val_acc: 0.7947\n",
      "Epoch 72/100\n",
      "8982/8982 [==============================] - 3s 289us/step - loss: 0.2313 - acc: 0.9413 - val_loss: 1.3178 - val_acc: 0.7934\n",
      "Epoch 73/100\n",
      "8982/8982 [==============================] - 3s 299us/step - loss: 0.2235 - acc: 0.9438 - val_loss: 1.3206 - val_acc: 0.7947\n",
      "Epoch 74/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2133 - acc: 0.9449 - val_loss: 1.3339 - val_acc: 0.7916\n",
      "Epoch 75/100\n",
      "8982/8982 [==============================] - 3s 287us/step - loss: 0.2131 - acc: 0.9446 - val_loss: 1.3508 - val_acc: 0.7979\n",
      "Epoch 76/100\n",
      "8982/8982 [==============================] - 3s 289us/step - loss: 0.2097 - acc: 0.9439 - val_loss: 1.3434 - val_acc: 0.7974\n",
      "Epoch 77/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.2235 - acc: 0.9427 - val_loss: 1.3455 - val_acc: 0.8005\n",
      "Epoch 78/100\n",
      "8982/8982 [==============================] - 3s 289us/step - loss: 0.2104 - acc: 0.9422 - val_loss: 1.3522 - val_acc: 0.7943\n",
      "Epoch 79/100\n",
      "8982/8982 [==============================] - 3s 299us/step - loss: 0.2049 - acc: 0.9464 - val_loss: 1.3517 - val_acc: 0.7952\n",
      "Epoch 80/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.2111 - acc: 0.9456 - val_loss: 1.3444 - val_acc: 0.7947\n",
      "Epoch 81/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.2179 - acc: 0.9421 - val_loss: 1.3626 - val_acc: 0.7979\n",
      "Epoch 82/100\n",
      "8982/8982 [==============================] - 3s 290us/step - loss: 0.2191 - acc: 0.9417 - val_loss: 1.3634 - val_acc: 0.7965\n",
      "Epoch 83/100\n",
      "8982/8982 [==============================] - 3s 301us/step - loss: 0.2058 - acc: 0.9452 - val_loss: 1.3494 - val_acc: 0.7996\n",
      "Epoch 84/100\n",
      "8982/8982 [==============================] - 3s 313us/step - loss: 0.2051 - acc: 0.9415 - val_loss: 1.3604 - val_acc: 0.7992\n",
      "Epoch 85/100\n",
      "8982/8982 [==============================] - 3s 323us/step - loss: 0.2151 - acc: 0.9441 - val_loss: 1.3430 - val_acc: 0.7965\n",
      "Epoch 86/100\n",
      "8982/8982 [==============================] - 3s 306us/step - loss: 0.2085 - acc: 0.9456 - val_loss: 1.3469 - val_acc: 0.7965\n",
      "Epoch 87/100\n",
      "8982/8982 [==============================] - 3s 292us/step - loss: 0.2054 - acc: 0.9442 - val_loss: 1.3432 - val_acc: 0.7983\n",
      "Epoch 88/100\n",
      "8982/8982 [==============================] - 3s 303us/step - loss: 0.1981 - acc: 0.9467 - val_loss: 1.3476 - val_acc: 0.7956\n",
      "Epoch 89/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.2017 - acc: 0.9470 - val_loss: 1.3600 - val_acc: 0.7988\n",
      "Epoch 90/100\n",
      "8982/8982 [==============================] - 3s 297us/step - loss: 0.2097 - acc: 0.9458 - val_loss: 1.3557 - val_acc: 0.7979\n",
      "Epoch 91/100\n",
      "8982/8982 [==============================] - 3s 311us/step - loss: 0.2039 - acc: 0.9450 - val_loss: 1.3554 - val_acc: 0.7979\n",
      "Epoch 92/100\n",
      "8982/8982 [==============================] - 3s 304us/step - loss: 0.1941 - acc: 0.9475 - val_loss: 1.3691 - val_acc: 0.8010\n",
      "Epoch 93/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2063 - acc: 0.9452 - val_loss: 1.3713 - val_acc: 0.8001\n",
      "Epoch 94/100\n",
      "8982/8982 [==============================] - 3s 297us/step - loss: 0.1992 - acc: 0.9456 - val_loss: 1.3799 - val_acc: 0.8005\n",
      "Epoch 95/100\n",
      "8982/8982 [==============================] - 3s 294us/step - loss: 0.1962 - acc: 0.9483 - val_loss: 1.3857 - val_acc: 0.7970\n",
      "Epoch 96/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2024 - acc: 0.9437 - val_loss: 1.3772 - val_acc: 0.7952\n",
      "Epoch 97/100\n",
      "8982/8982 [==============================] - 3s 310us/step - loss: 0.2109 - acc: 0.9422 - val_loss: 1.3713 - val_acc: 0.7988\n",
      "Epoch 98/100\n",
      "8982/8982 [==============================] - 3s 301us/step - loss: 0.1994 - acc: 0.9429 - val_loss: 1.3652 - val_acc: 0.7974\n",
      "Epoch 99/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.2044 - acc: 0.9461 - val_loss: 1.3548 - val_acc: 0.7979\n",
      "Epoch 100/100\n",
      "8982/8982 [==============================] - 3s 296us/step - loss: 0.1920 - acc: 0.9479 - val_loss: 1.3703 - val_acc: 0.7974\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x280f7900dd8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=256, epochs=100, verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
